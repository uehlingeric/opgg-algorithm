{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Implementation with Specific Column Set\n",
    "\n",
    "(used for separate project, just ignore this file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "output_dir = \"../outputs/nn\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>champ</th>\n",
       "      <th>position</th>\n",
       "      <th>op_score</th>\n",
       "      <th>win</th>\n",
       "      <th>length</th>\n",
       "      <th>kill</th>\n",
       "      <th>death</th>\n",
       "      <th>assist</th>\n",
       "      <th>kda</th>\n",
       "      <th>dmg</th>\n",
       "      <th>...</th>\n",
       "      <th>dmg_taken_perc</th>\n",
       "      <th>gold_perc</th>\n",
       "      <th>dmg_per_gold</th>\n",
       "      <th>pinks_bought</th>\n",
       "      <th>ward_kill</th>\n",
       "      <th>ward_place</th>\n",
       "      <th>cs_diff</th>\n",
       "      <th>gold_diff</th>\n",
       "      <th>level_diff</th>\n",
       "      <th>dmg_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kai'Sa</td>\n",
       "      <td>ADC</td>\n",
       "      <td>2.706</td>\n",
       "      <td>0</td>\n",
       "      <td>27.117</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.333</td>\n",
       "      <td>15557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.215</td>\n",
       "      <td>1.591</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>-1796</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kindred</td>\n",
       "      <td>JUNGLE</td>\n",
       "      <td>1.253</td>\n",
       "      <td>0</td>\n",
       "      <td>27.117</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667</td>\n",
       "      <td>17786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.197</td>\n",
       "      <td>1.984</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-50</td>\n",
       "      <td>-3741</td>\n",
       "      <td>-2</td>\n",
       "      <td>1534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahri</td>\n",
       "      <td>MID</td>\n",
       "      <td>3.671</td>\n",
       "      <td>0</td>\n",
       "      <td>27.117</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.000</td>\n",
       "      <td>17686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.207</td>\n",
       "      <td>1.879</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-7</td>\n",
       "      <td>-2547</td>\n",
       "      <td>-1</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aatrox</td>\n",
       "      <td>TOP</td>\n",
       "      <td>1.777</td>\n",
       "      <td>0</td>\n",
       "      <td>27.117</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667</td>\n",
       "      <td>17220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.227</td>\n",
       "      <td>1.666</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>-982</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nautilus</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>2.501</td>\n",
       "      <td>0</td>\n",
       "      <td>27.117</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.333</td>\n",
       "      <td>6797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.963</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>-6</td>\n",
       "      <td>-425</td>\n",
       "      <td>-2</td>\n",
       "      <td>2855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      champ position  op_score  win  length  kill  death  assist    kda  \\\n",
       "0    Kai'Sa      ADC     2.706    0  27.117     1      3       3  1.333   \n",
       "1   Kindred   JUNGLE     1.253    0  27.117     2      6       2  0.667   \n",
       "2      Ahri      MID     3.671    0  27.117     2      1       2  4.000   \n",
       "3    Aatrox      TOP     1.777    0  27.117     2      6       2  0.667   \n",
       "4  Nautilus  SUPPORT     2.501    0  27.117     3      6       5  1.333   \n",
       "\n",
       "     dmg  ...  dmg_taken_perc  gold_perc  dmg_per_gold  pinks_bought  \\\n",
       "0  15557  ...           0.133      0.215         1.591             2   \n",
       "1  17786  ...           0.280      0.197         1.984             0   \n",
       "2  17686  ...           0.098      0.207         1.879             5   \n",
       "3  17220  ...           0.311      0.227         1.666             0   \n",
       "4   6797  ...           0.178      0.155         0.963             6   \n",
       "\n",
       "   ward_kill  ward_place  cs_diff  gold_diff  level_diff  dmg_diff  \n",
       "0          2           9        3      -1796          -1     -2384  \n",
       "1          3           1      -50      -3741          -2      1534  \n",
       "2          1          13       -7      -2547          -1      2770  \n",
       "3          4           6       21       -982          -1     -4790  \n",
       "4         12          37       -6       -425          -2      2855  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/processed/games.csv\")\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = [\n",
    "    \"magic_dmg\",\n",
    "    \"ad_dmg\",\n",
    "    \"all_dmg\",\n",
    "    \"ad_dmg_taken\",\n",
    "    \"total_heal\",\n",
    "    \"turret_kill\",\n",
    "    \"inhib_kill\",\n",
    "    \"objective_dmg\",\n",
    "    \"turret_dmg\",\n",
    "    \"largest_multi_kill\",\n",
    "    \"largest_kill_spree\",\n",
    "    \"cc_score\",\n",
    "    \"vision\",\n",
    "    \"dmg_taken_diff\",\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204390, 197), (204390, 30), (204390,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the preprocessing for numerical features\n",
    "numerical_features = [\n",
    "    \"length\",\n",
    "    \"kill\",\n",
    "    \"death\",\n",
    "    \"assist\",\n",
    "    \"kda\",\n",
    "    \"dmg\",\n",
    "    \"dmg_taken\",\n",
    "    \"mitigated_dmg\",\n",
    "    \"cs\",\n",
    "    \"gold\",\n",
    "    \"level\",\n",
    "    \"kp\",\n",
    "    \"dmg_perc\",\n",
    "    \"dmg_taken_perc\",\n",
    "    \"gold_perc\",\n",
    "    \"dmg_per_gold\",\n",
    "    \"pinks_bought\",\n",
    "    \"ward_kill\",\n",
    "    \"ward_place\",\n",
    "    \"cs_diff\",\n",
    "    \"gold_diff\",\n",
    "    \"level_diff\",\n",
    "    \"dmg_diff\",\n",
    "]\n",
    "\n",
    "# Use QuantileTransformer for numerical features\n",
    "quantile_transformer = Pipeline(\n",
    "    steps=[(\"quantile\", QuantileTransformer(output_distribution=\"normal\"))]\n",
    ")\n",
    "\n",
    "# Define the preprocessing for categorical features with champ\n",
    "categorical_features_with_champ = [\"champ\", \"position\", \"win\"]\n",
    "\n",
    "# Use OneHotEncoder for categorical features\n",
    "categorical_transformer_with_champ = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "# Combine all preprocessing steps into a single ColumnTransformer for champ\n",
    "preprocessor_with_champ = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", quantile_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer_with_champ, categorical_features_with_champ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing with champ\n",
    "X_with_champ = preprocessor_with_champ.fit_transform(df.drop(\"op_score\", axis=1))\n",
    "y = df[\"op_score\"].values\n",
    "preprocessor_with_champ.fit(df.drop(\"op_score\", axis=1))\n",
    "\n",
    "# Save the preprocessor with champ\n",
    "joblib.dump(preprocessor_with_champ, \"../outputs/nn/vt_preprocessor_with_champ.pkl\")\n",
    "\n",
    "# Define the preprocessing for categorical features without champ\n",
    "categorical_features_without_champ = [\"position\", \"win\"]\n",
    "\n",
    "# Use OneHotEncoder for categorical features\n",
    "categorical_transformer_without_champ = Pipeline(\n",
    "    steps=[(\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
    ")\n",
    "\n",
    "# Combine all preprocessing steps into a single ColumnTransformer without champ\n",
    "preprocessor_without_champ = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", quantile_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer_without_champ, categorical_features_without_champ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the preprocessing without champ\n",
    "X_without_champ = preprocessor_without_champ.fit_transform(df.drop(\"op_score\", axis=1))\n",
    "preprocessor_without_champ.fit(df.drop(\"op_score\", axis=1))\n",
    "\n",
    "# Save the preprocessor without champ\n",
    "joblib.dump(preprocessor_without_champ, \"../outputs/nn/vt_preprocessor_without_champ.pkl\")\n",
    "\n",
    "# Check the shapes of X and y\n",
    "X_with_champ.shape, X_without_champ.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "y = df[\"op_score\"].values\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_with_champ, X_test_with_champ, y_train, y_test = train_test_split(\n",
    "    X_with_champ, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_without_champ, X_test_without_champ, _, _ = train_test_split(\n",
    "    X_without_champ, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create and compile the model\n",
    "def create_and_compile_model(input_shape):\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(128, activation=\"relu\", input_shape=(input_shape,)),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_squared_error\", \"mean_absolute_error\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eric\\anaconda3\\envs\\opgg\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 796us/step - loss: 1.2023 - mean_absolute_error: 0.6813 - mean_squared_error: 1.2023 - val_loss: 0.3327 - val_mean_absolute_error: 0.4532 - val_mean_squared_error: 0.3327\n",
      "Epoch 2/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 779us/step - loss: 0.3318 - mean_absolute_error: 0.4540 - mean_squared_error: 0.3318 - val_loss: 0.3149 - val_mean_absolute_error: 0.4406 - val_mean_squared_error: 0.3149\n",
      "Epoch 3/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 765us/step - loss: 0.3150 - mean_absolute_error: 0.4415 - mean_squared_error: 0.3150 - val_loss: 0.3141 - val_mean_absolute_error: 0.4398 - val_mean_squared_error: 0.3141\n",
      "Epoch 4/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 762us/step - loss: 0.3083 - mean_absolute_error: 0.4355 - mean_squared_error: 0.3083 - val_loss: 0.3105 - val_mean_absolute_error: 0.4352 - val_mean_squared_error: 0.3105\n",
      "Epoch 5/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 756us/step - loss: 0.3028 - mean_absolute_error: 0.4322 - mean_squared_error: 0.3028 - val_loss: 0.3054 - val_mean_absolute_error: 0.4331 - val_mean_squared_error: 0.3054\n",
      "Epoch 6/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 761us/step - loss: 0.2959 - mean_absolute_error: 0.4266 - mean_squared_error: 0.2959 - val_loss: 0.3170 - val_mean_absolute_error: 0.4423 - val_mean_squared_error: 0.3170\n",
      "Epoch 7/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 758us/step - loss: 0.2928 - mean_absolute_error: 0.4236 - mean_squared_error: 0.2928 - val_loss: 0.3037 - val_mean_absolute_error: 0.4322 - val_mean_squared_error: 0.3037\n",
      "Epoch 8/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 766us/step - loss: 0.2872 - mean_absolute_error: 0.4204 - mean_squared_error: 0.2872 - val_loss: 0.3039 - val_mean_absolute_error: 0.4306 - val_mean_squared_error: 0.3039\n",
      "Epoch 9/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 770us/step - loss: 0.2867 - mean_absolute_error: 0.4203 - mean_squared_error: 0.2867 - val_loss: 0.3010 - val_mean_absolute_error: 0.4286 - val_mean_squared_error: 0.3010\n",
      "Epoch 10/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 767us/step - loss: 0.2839 - mean_absolute_error: 0.4181 - mean_squared_error: 0.2839 - val_loss: 0.3327 - val_mean_absolute_error: 0.4514 - val_mean_squared_error: 0.3327\n",
      "Epoch 11/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 759us/step - loss: 0.2828 - mean_absolute_error: 0.4167 - mean_squared_error: 0.2828 - val_loss: 0.3053 - val_mean_absolute_error: 0.4311 - val_mean_squared_error: 0.3053\n",
      "Epoch 12/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 773us/step - loss: 0.2766 - mean_absolute_error: 0.4124 - mean_squared_error: 0.2766 - val_loss: 0.3004 - val_mean_absolute_error: 0.4288 - val_mean_squared_error: 0.3004\n",
      "Epoch 13/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 770us/step - loss: 0.2780 - mean_absolute_error: 0.4131 - mean_squared_error: 0.2780 - val_loss: 0.3143 - val_mean_absolute_error: 0.4377 - val_mean_squared_error: 0.3143\n",
      "Epoch 14/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 767us/step - loss: 0.2749 - mean_absolute_error: 0.4108 - mean_squared_error: 0.2749 - val_loss: 0.3009 - val_mean_absolute_error: 0.4280 - val_mean_squared_error: 0.3009\n",
      "Epoch 15/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 763us/step - loss: 0.2714 - mean_absolute_error: 0.4086 - mean_squared_error: 0.2714 - val_loss: 0.3007 - val_mean_absolute_error: 0.4275 - val_mean_squared_error: 0.3007\n",
      "Epoch 16/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 759us/step - loss: 0.2701 - mean_absolute_error: 0.4078 - mean_squared_error: 0.2701 - val_loss: 0.3011 - val_mean_absolute_error: 0.4283 - val_mean_squared_error: 0.3011\n",
      "Epoch 17/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 764us/step - loss: 0.2699 - mean_absolute_error: 0.4073 - mean_squared_error: 0.2699 - val_loss: 0.3051 - val_mean_absolute_error: 0.4311 - val_mean_squared_error: 0.3051\n",
      "Epoch 18/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 763us/step - loss: 0.2660 - mean_absolute_error: 0.4036 - mean_squared_error: 0.2660 - val_loss: 0.3030 - val_mean_absolute_error: 0.4297 - val_mean_squared_error: 0.3030\n",
      "Epoch 19/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 752us/step - loss: 0.2636 - mean_absolute_error: 0.4029 - mean_squared_error: 0.2636 - val_loss: 0.3035 - val_mean_absolute_error: 0.4296 - val_mean_squared_error: 0.3035\n",
      "Epoch 20/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 770us/step - loss: 0.2645 - mean_absolute_error: 0.4028 - mean_squared_error: 0.2645 - val_loss: 0.3049 - val_mean_absolute_error: 0.4302 - val_mean_squared_error: 0.3049\n",
      "Epoch 21/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 766us/step - loss: 0.2628 - mean_absolute_error: 0.4014 - mean_squared_error: 0.2628 - val_loss: 0.3021 - val_mean_absolute_error: 0.4295 - val_mean_squared_error: 0.3021\n",
      "Epoch 22/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 767us/step - loss: 0.2603 - mean_absolute_error: 0.3991 - mean_squared_error: 0.2603 - val_loss: 0.3056 - val_mean_absolute_error: 0.4309 - val_mean_squared_error: 0.3056\n",
      "Epoch 23/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 759us/step - loss: 0.2581 - mean_absolute_error: 0.3979 - mean_squared_error: 0.2581 - val_loss: 0.3080 - val_mean_absolute_error: 0.4334 - val_mean_squared_error: 0.3080\n",
      "Epoch 24/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 756us/step - loss: 0.2571 - mean_absolute_error: 0.3969 - mean_squared_error: 0.2571 - val_loss: 0.3063 - val_mean_absolute_error: 0.4336 - val_mean_squared_error: 0.3063\n",
      "Epoch 25/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 770us/step - loss: 0.2555 - mean_absolute_error: 0.3957 - mean_squared_error: 0.2555 - val_loss: 0.3092 - val_mean_absolute_error: 0.4339 - val_mean_squared_error: 0.3092\n",
      "Epoch 26/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 772us/step - loss: 0.2539 - mean_absolute_error: 0.3945 - mean_squared_error: 0.2539 - val_loss: 0.3084 - val_mean_absolute_error: 0.4325 - val_mean_squared_error: 0.3084\n",
      "Epoch 27/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 784us/step - loss: 0.2548 - mean_absolute_error: 0.3955 - mean_squared_error: 0.2548 - val_loss: 0.3121 - val_mean_absolute_error: 0.4355 - val_mean_squared_error: 0.3121\n",
      "Epoch 28/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 778us/step - loss: 0.2511 - mean_absolute_error: 0.3919 - mean_squared_error: 0.2511 - val_loss: 0.3085 - val_mean_absolute_error: 0.4327 - val_mean_squared_error: 0.3085\n",
      "Epoch 29/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 773us/step - loss: 0.2491 - mean_absolute_error: 0.3906 - mean_squared_error: 0.2491 - val_loss: 0.3117 - val_mean_absolute_error: 0.4359 - val_mean_squared_error: 0.3117\n",
      "Epoch 30/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 783us/step - loss: 0.2478 - mean_absolute_error: 0.3898 - mean_squared_error: 0.2478 - val_loss: 0.3115 - val_mean_absolute_error: 0.4357 - val_mean_squared_error: 0.3115\n",
      "Epoch 31/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 768us/step - loss: 0.2519 - mean_absolute_error: 0.3924 - mean_squared_error: 0.2519 - val_loss: 0.3138 - val_mean_absolute_error: 0.4365 - val_mean_squared_error: 0.3138\n",
      "Epoch 32/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 762us/step - loss: 0.2472 - mean_absolute_error: 0.3886 - mean_squared_error: 0.2472 - val_loss: 0.3137 - val_mean_absolute_error: 0.4362 - val_mean_squared_error: 0.3137\n",
      "Epoch 33/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 771us/step - loss: 0.2452 - mean_absolute_error: 0.3869 - mean_squared_error: 0.2452 - val_loss: 0.3109 - val_mean_absolute_error: 0.4351 - val_mean_squared_error: 0.3109\n",
      "Epoch 34/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 774us/step - loss: 0.2442 - mean_absolute_error: 0.3868 - mean_squared_error: 0.2442 - val_loss: 0.3165 - val_mean_absolute_error: 0.4398 - val_mean_squared_error: 0.3165\n",
      "Epoch 35/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 769us/step - loss: 0.2439 - mean_absolute_error: 0.3859 - mean_squared_error: 0.2439 - val_loss: 0.3154 - val_mean_absolute_error: 0.4390 - val_mean_squared_error: 0.3154\n",
      "Epoch 36/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 762us/step - loss: 0.2421 - mean_absolute_error: 0.3847 - mean_squared_error: 0.2421 - val_loss: 0.3238 - val_mean_absolute_error: 0.4432 - val_mean_squared_error: 0.3238\n",
      "Epoch 37/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 761us/step - loss: 0.2441 - mean_absolute_error: 0.3866 - mean_squared_error: 0.2441 - val_loss: 0.3192 - val_mean_absolute_error: 0.4402 - val_mean_squared_error: 0.3192\n",
      "Epoch 38/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 768us/step - loss: 0.2401 - mean_absolute_error: 0.3828 - mean_squared_error: 0.2401 - val_loss: 0.3134 - val_mean_absolute_error: 0.4357 - val_mean_squared_error: 0.3134\n",
      "Epoch 39/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 776us/step - loss: 0.2399 - mean_absolute_error: 0.3829 - mean_squared_error: 0.2399 - val_loss: 0.3249 - val_mean_absolute_error: 0.4451 - val_mean_squared_error: 0.3249\n",
      "Epoch 40/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 783us/step - loss: 0.2409 - mean_absolute_error: 0.3835 - mean_squared_error: 0.2409 - val_loss: 0.3257 - val_mean_absolute_error: 0.4475 - val_mean_squared_error: 0.3257\n",
      "Epoch 41/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 765us/step - loss: 0.2380 - mean_absolute_error: 0.3818 - mean_squared_error: 0.2380 - val_loss: 0.3193 - val_mean_absolute_error: 0.4397 - val_mean_squared_error: 0.3193\n",
      "Epoch 42/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 768us/step - loss: 0.2384 - mean_absolute_error: 0.3815 - mean_squared_error: 0.2384 - val_loss: 0.3207 - val_mean_absolute_error: 0.4435 - val_mean_squared_error: 0.3207\n",
      "Epoch 43/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 763us/step - loss: 0.2349 - mean_absolute_error: 0.3790 - mean_squared_error: 0.2349 - val_loss: 0.3157 - val_mean_absolute_error: 0.4364 - val_mean_squared_error: 0.3157\n",
      "Epoch 44/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 774us/step - loss: 0.2360 - mean_absolute_error: 0.3797 - mean_squared_error: 0.2360 - val_loss: 0.3234 - val_mean_absolute_error: 0.4427 - val_mean_squared_error: 0.3234\n",
      "Epoch 45/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 766us/step - loss: 0.2341 - mean_absolute_error: 0.3781 - mean_squared_error: 0.2341 - val_loss: 0.3186 - val_mean_absolute_error: 0.4393 - val_mean_squared_error: 0.3186\n",
      "Epoch 46/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 766us/step - loss: 0.2346 - mean_absolute_error: 0.3787 - mean_squared_error: 0.2346 - val_loss: 0.3190 - val_mean_absolute_error: 0.4391 - val_mean_squared_error: 0.3190\n",
      "Epoch 47/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 771us/step - loss: 0.2339 - mean_absolute_error: 0.3779 - mean_squared_error: 0.2339 - val_loss: 0.3187 - val_mean_absolute_error: 0.4403 - val_mean_squared_error: 0.3187\n",
      "Epoch 48/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 774us/step - loss: 0.2324 - mean_absolute_error: 0.3767 - mean_squared_error: 0.2324 - val_loss: 0.3284 - val_mean_absolute_error: 0.4477 - val_mean_squared_error: 0.3284\n",
      "Epoch 49/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 775us/step - loss: 0.2322 - mean_absolute_error: 0.3762 - mean_squared_error: 0.2322 - val_loss: 0.3233 - val_mean_absolute_error: 0.4432 - val_mean_squared_error: 0.3233\n",
      "Epoch 50/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 773us/step - loss: 0.2317 - mean_absolute_error: 0.3763 - mean_squared_error: 0.2317 - val_loss: 0.3240 - val_mean_absolute_error: 0.4436 - val_mean_squared_error: 0.3240\n",
      "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - loss: 0.3232 - mean_absolute_error: 0.4444 - mean_squared_error: 0.3232\n",
      "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with champ - Mean Squared Error: 0.3239996163648315\n",
      "Model with champ - R^2 Score: 0.9333396764050576\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model with champ data\n",
    "model_with_champ = create_and_compile_model(X_train_with_champ.shape[1])\n",
    "history_with_champ = model_with_champ.fit(\n",
    "    X_train_with_champ, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1\n",
    ")\n",
    "test_results_with_champ = model_with_champ.evaluate(X_test_with_champ, y_test, verbose=1)\n",
    "y_pred_with_champ = model_with_champ.predict(X_test_with_champ)\n",
    "mse_with_champ = mean_squared_error(y_test, y_pred_with_champ)\n",
    "r2_with_champ = r2_score(y_test, y_pred_with_champ)\n",
    "print(f\"Model with champ - Mean Squared Error: {mse_with_champ}\")\n",
    "print(f\"Model with champ - R^2 Score: {r2_with_champ}\")\n",
    "model_with_champ.save(os.path.join(output_dir, \"model_with_champ.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eric\\anaconda3\\envs\\opgg\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 691us/step - loss: 1.1605 - mean_absolute_error: 0.6768 - mean_squared_error: 1.1605 - val_loss: 0.3398 - val_mean_absolute_error: 0.4575 - val_mean_squared_error: 0.3398\n",
      "Epoch 2/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 660us/step - loss: 0.3328 - mean_absolute_error: 0.4543 - mean_squared_error: 0.3328 - val_loss: 0.3123 - val_mean_absolute_error: 0.4386 - val_mean_squared_error: 0.3123\n",
      "Epoch 3/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 662us/step - loss: 0.3193 - mean_absolute_error: 0.4441 - mean_squared_error: 0.3193 - val_loss: 0.3121 - val_mean_absolute_error: 0.4386 - val_mean_squared_error: 0.3121\n",
      "Epoch 4/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 672us/step - loss: 0.3133 - mean_absolute_error: 0.4395 - mean_squared_error: 0.3133 - val_loss: 0.3127 - val_mean_absolute_error: 0.4381 - val_mean_squared_error: 0.3127\n",
      "Epoch 5/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 662us/step - loss: 0.3080 - mean_absolute_error: 0.4357 - mean_squared_error: 0.3080 - val_loss: 0.3046 - val_mean_absolute_error: 0.4325 - val_mean_squared_error: 0.3046\n",
      "Epoch 6/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707us/step - loss: 0.3014 - mean_absolute_error: 0.4310 - mean_squared_error: 0.3014 - val_loss: 0.3155 - val_mean_absolute_error: 0.4395 - val_mean_squared_error: 0.3155\n",
      "Epoch 7/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 687us/step - loss: 0.3034 - mean_absolute_error: 0.4327 - mean_squared_error: 0.3034 - val_loss: 0.3271 - val_mean_absolute_error: 0.4498 - val_mean_squared_error: 0.3271\n",
      "Epoch 8/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 677us/step - loss: 0.3008 - mean_absolute_error: 0.4295 - mean_squared_error: 0.3008 - val_loss: 0.3008 - val_mean_absolute_error: 0.4294 - val_mean_squared_error: 0.3008\n",
      "Epoch 9/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 669us/step - loss: 0.2960 - mean_absolute_error: 0.4269 - mean_squared_error: 0.2960 - val_loss: 0.2984 - val_mean_absolute_error: 0.4266 - val_mean_squared_error: 0.2984\n",
      "Epoch 10/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 652us/step - loss: 0.2973 - mean_absolute_error: 0.4276 - mean_squared_error: 0.2973 - val_loss: 0.3073 - val_mean_absolute_error: 0.4363 - val_mean_squared_error: 0.3073\n",
      "Epoch 11/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 656us/step - loss: 0.2945 - mean_absolute_error: 0.4251 - mean_squared_error: 0.2945 - val_loss: 0.2988 - val_mean_absolute_error: 0.4275 - val_mean_squared_error: 0.2988\n",
      "Epoch 12/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 663us/step - loss: 0.2924 - mean_absolute_error: 0.4232 - mean_squared_error: 0.2924 - val_loss: 0.2992 - val_mean_absolute_error: 0.4274 - val_mean_squared_error: 0.2992\n",
      "Epoch 13/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 658us/step - loss: 0.2906 - mean_absolute_error: 0.4224 - mean_squared_error: 0.2906 - val_loss: 0.3166 - val_mean_absolute_error: 0.4412 - val_mean_squared_error: 0.3166\n",
      "Epoch 14/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 654us/step - loss: 0.2908 - mean_absolute_error: 0.4228 - mean_squared_error: 0.2908 - val_loss: 0.2942 - val_mean_absolute_error: 0.4245 - val_mean_squared_error: 0.2942\n",
      "Epoch 15/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 653us/step - loss: 0.2902 - mean_absolute_error: 0.4220 - mean_squared_error: 0.2902 - val_loss: 0.2926 - val_mean_absolute_error: 0.4237 - val_mean_squared_error: 0.2926\n",
      "Epoch 16/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 656us/step - loss: 0.2892 - mean_absolute_error: 0.4211 - mean_squared_error: 0.2892 - val_loss: 0.3047 - val_mean_absolute_error: 0.4317 - val_mean_squared_error: 0.3047\n",
      "Epoch 17/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 669us/step - loss: 0.2896 - mean_absolute_error: 0.4213 - mean_squared_error: 0.2896 - val_loss: 0.2949 - val_mean_absolute_error: 0.4244 - val_mean_squared_error: 0.2949\n",
      "Epoch 18/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 655us/step - loss: 0.2888 - mean_absolute_error: 0.4211 - mean_squared_error: 0.2888 - val_loss: 0.2977 - val_mean_absolute_error: 0.4287 - val_mean_squared_error: 0.2977\n",
      "Epoch 19/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 652us/step - loss: 0.2865 - mean_absolute_error: 0.4196 - mean_squared_error: 0.2865 - val_loss: 0.2958 - val_mean_absolute_error: 0.4259 - val_mean_squared_error: 0.2958\n",
      "Epoch 20/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 677us/step - loss: 0.2844 - mean_absolute_error: 0.4173 - mean_squared_error: 0.2844 - val_loss: 0.3051 - val_mean_absolute_error: 0.4309 - val_mean_squared_error: 0.3051\n",
      "Epoch 21/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 713us/step - loss: 0.2851 - mean_absolute_error: 0.4175 - mean_squared_error: 0.2851 - val_loss: 0.2968 - val_mean_absolute_error: 0.4255 - val_mean_squared_error: 0.2968\n",
      "Epoch 22/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 670us/step - loss: 0.2833 - mean_absolute_error: 0.4167 - mean_squared_error: 0.2833 - val_loss: 0.2953 - val_mean_absolute_error: 0.4241 - val_mean_squared_error: 0.2953\n",
      "Epoch 23/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 663us/step - loss: 0.2797 - mean_absolute_error: 0.4139 - mean_squared_error: 0.2797 - val_loss: 0.2944 - val_mean_absolute_error: 0.4236 - val_mean_squared_error: 0.2944\n",
      "Epoch 24/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 662us/step - loss: 0.2822 - mean_absolute_error: 0.4165 - mean_squared_error: 0.2822 - val_loss: 0.2956 - val_mean_absolute_error: 0.4266 - val_mean_squared_error: 0.2956\n",
      "Epoch 25/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 671us/step - loss: 0.2815 - mean_absolute_error: 0.4154 - mean_squared_error: 0.2815 - val_loss: 0.2955 - val_mean_absolute_error: 0.4247 - val_mean_squared_error: 0.2955\n",
      "Epoch 26/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 669us/step - loss: 0.2795 - mean_absolute_error: 0.4148 - mean_squared_error: 0.2795 - val_loss: 0.2941 - val_mean_absolute_error: 0.4239 - val_mean_squared_error: 0.2941\n",
      "Epoch 27/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 662us/step - loss: 0.2790 - mean_absolute_error: 0.4140 - mean_squared_error: 0.2790 - val_loss: 0.2944 - val_mean_absolute_error: 0.4275 - val_mean_squared_error: 0.2944\n",
      "Epoch 28/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 659us/step - loss: 0.2785 - mean_absolute_error: 0.4132 - mean_squared_error: 0.2785 - val_loss: 0.2968 - val_mean_absolute_error: 0.4253 - val_mean_squared_error: 0.2968\n",
      "Epoch 29/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 664us/step - loss: 0.2777 - mean_absolute_error: 0.4130 - mean_squared_error: 0.2777 - val_loss: 0.2989 - val_mean_absolute_error: 0.4283 - val_mean_squared_error: 0.2989\n",
      "Epoch 30/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 664us/step - loss: 0.2796 - mean_absolute_error: 0.4138 - mean_squared_error: 0.2796 - val_loss: 0.2994 - val_mean_absolute_error: 0.4284 - val_mean_squared_error: 0.2994\n",
      "Epoch 31/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 658us/step - loss: 0.2774 - mean_absolute_error: 0.4127 - mean_squared_error: 0.2774 - val_loss: 0.3087 - val_mean_absolute_error: 0.4352 - val_mean_squared_error: 0.3087\n",
      "Epoch 32/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 668us/step - loss: 0.2779 - mean_absolute_error: 0.4135 - mean_squared_error: 0.2779 - val_loss: 0.2958 - val_mean_absolute_error: 0.4258 - val_mean_squared_error: 0.2958\n",
      "Epoch 33/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 673us/step - loss: 0.2767 - mean_absolute_error: 0.4123 - mean_squared_error: 0.2767 - val_loss: 0.2950 - val_mean_absolute_error: 0.4236 - val_mean_squared_error: 0.2950\n",
      "Epoch 34/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 667us/step - loss: 0.2775 - mean_absolute_error: 0.4123 - mean_squared_error: 0.2775 - val_loss: 0.2970 - val_mean_absolute_error: 0.4256 - val_mean_squared_error: 0.2970\n",
      "Epoch 35/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 666us/step - loss: 0.2754 - mean_absolute_error: 0.4113 - mean_squared_error: 0.2754 - val_loss: 0.2989 - val_mean_absolute_error: 0.4264 - val_mean_squared_error: 0.2989\n",
      "Epoch 36/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 660us/step - loss: 0.2765 - mean_absolute_error: 0.4120 - mean_squared_error: 0.2765 - val_loss: 0.2938 - val_mean_absolute_error: 0.4233 - val_mean_squared_error: 0.2938\n",
      "Epoch 37/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 664us/step - loss: 0.2747 - mean_absolute_error: 0.4110 - mean_squared_error: 0.2747 - val_loss: 0.2988 - val_mean_absolute_error: 0.4269 - val_mean_squared_error: 0.2988\n",
      "Epoch 38/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 672us/step - loss: 0.2736 - mean_absolute_error: 0.4096 - mean_squared_error: 0.2736 - val_loss: 0.2960 - val_mean_absolute_error: 0.4248 - val_mean_squared_error: 0.2960\n",
      "Epoch 39/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 669us/step - loss: 0.2744 - mean_absolute_error: 0.4104 - mean_squared_error: 0.2744 - val_loss: 0.2990 - val_mean_absolute_error: 0.4276 - val_mean_squared_error: 0.2990\n",
      "Epoch 40/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 664us/step - loss: 0.2725 - mean_absolute_error: 0.4088 - mean_squared_error: 0.2725 - val_loss: 0.2959 - val_mean_absolute_error: 0.4262 - val_mean_squared_error: 0.2959\n",
      "Epoch 41/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 666us/step - loss: 0.2731 - mean_absolute_error: 0.4096 - mean_squared_error: 0.2731 - val_loss: 0.2953 - val_mean_absolute_error: 0.4244 - val_mean_squared_error: 0.2953\n",
      "Epoch 42/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 668us/step - loss: 0.2742 - mean_absolute_error: 0.4101 - mean_squared_error: 0.2742 - val_loss: 0.2963 - val_mean_absolute_error: 0.4243 - val_mean_squared_error: 0.2963\n",
      "Epoch 43/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 676us/step - loss: 0.2733 - mean_absolute_error: 0.4088 - mean_squared_error: 0.2733 - val_loss: 0.3166 - val_mean_absolute_error: 0.4399 - val_mean_squared_error: 0.3166\n",
      "Epoch 44/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 668us/step - loss: 0.2727 - mean_absolute_error: 0.4083 - mean_squared_error: 0.2727 - val_loss: 0.3030 - val_mean_absolute_error: 0.4314 - val_mean_squared_error: 0.3030\n",
      "Epoch 45/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 667us/step - loss: 0.2717 - mean_absolute_error: 0.4079 - mean_squared_error: 0.2717 - val_loss: 0.2972 - val_mean_absolute_error: 0.4251 - val_mean_squared_error: 0.2972\n",
      "Epoch 46/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 668us/step - loss: 0.2716 - mean_absolute_error: 0.4082 - mean_squared_error: 0.2716 - val_loss: 0.2963 - val_mean_absolute_error: 0.4257 - val_mean_squared_error: 0.2963\n",
      "Epoch 47/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 674us/step - loss: 0.2711 - mean_absolute_error: 0.4078 - mean_squared_error: 0.2711 - val_loss: 0.3019 - val_mean_absolute_error: 0.4288 - val_mean_squared_error: 0.3019\n",
      "Epoch 48/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 662us/step - loss: 0.2715 - mean_absolute_error: 0.4079 - mean_squared_error: 0.2715 - val_loss: 0.2989 - val_mean_absolute_error: 0.4268 - val_mean_squared_error: 0.2989\n",
      "Epoch 49/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 663us/step - loss: 0.2693 - mean_absolute_error: 0.4062 - mean_squared_error: 0.2693 - val_loss: 0.2974 - val_mean_absolute_error: 0.4262 - val_mean_squared_error: 0.2974\n",
      "Epoch 50/50\n",
      "\u001b[1m4088/4088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 665us/step - loss: 0.2682 - mean_absolute_error: 0.4051 - mean_squared_error: 0.2682 - val_loss: 0.2985 - val_mean_absolute_error: 0.4265 - val_mean_squared_error: 0.2985\n",
      "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - loss: 0.2972 - mean_absolute_error: 0.4261 - mean_squared_error: 0.2972\n",
      "\u001b[1m1278/1278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 482us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model without champ - Mean Squared Error: 0.2969577344685292\n",
      "Model without champ - R^2 Score: 0.9389033268131923\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model without champ data\n",
    "model_without_champ = create_and_compile_model(X_train_without_champ.shape[1])\n",
    "history_without_champ = model_without_champ.fit(\n",
    "    X_train_without_champ, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1\n",
    ")\n",
    "test_results_without_champ = model_without_champ.evaluate(X_test_without_champ, y_test, verbose=1)\n",
    "y_pred_without_champ = model_without_champ.predict(X_test_without_champ)\n",
    "mse_without_champ = mean_squared_error(y_test, y_pred_without_champ)\n",
    "r2_without_champ = r2_score(y_test, y_pred_without_champ)\n",
    "print(f\"Model without champ - Mean Squared Error: {mse_without_champ}\")\n",
    "print(f\"Model without champ - R^2 Score: {r2_without_champ}\")\n",
    "model_without_champ.save(os.path.join(output_dir, \"model_without_champ.h5\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
